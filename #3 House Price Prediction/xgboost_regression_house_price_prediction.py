# -*- coding: utf-8 -*-
"""XGBoost Regression House Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17DyHYFaMl5-ly9cX5qOa6jnbeHMh1jkb

Importing the Dependices
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""Importing Boston House Price Dataset"""

house_price_data = sklearn.datasets.load_boston() 
# () -> one instance of this dataset

print(house_price_data)

# loading dataset to pandas DataFrame
house_price_dataframe = pd.DataFrame(house_price_data.data,columns=house_price_data.feature_names)

# printing first five rows of dataset
house_price_dataframe.head()

# adding target(price) column to DataFrame
house_price_dataframe['price'] = house_price_data.target

print(house_price_dataframe)

house_price_dataframe.head()

# checking number of rows and columns
house_price_dataframe.shape

# check for missing value - if there is some missing then we need to dropping or imutation
house_price_dataframe.isnull().sum()

# statistical measure of dataframe
house_price_dataframe.describe()

"""Understanding the corelation between various feature in the dataset ðŸ”¥

Correlation - relationship between two variable
It is of two type
1. Positive Correlation
2. Negative Correlation
"""

correlation = house_price_dataframe.corr()

print(correlation)

# constructing a heatmap to understanding the correlation 
plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f', annot=True, annot_kws={'size': 8},cmap='Greens')

#  cbar  =   color bar ( it have +ve value which represent positive correlation & vice versa)
#  fmt   =   how many float value we want 
#  annot =   annotation mean column name in heat map
#  annot_kws = size

"""Splitting data and target"""

x = house_price_dataframe.drop(columns='price',axis=1)
y = house_price_dataframe['price']
print(x,y)

"""Splitting data into training data and test data"""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 2)
print(x_train,y_train)

x.shape, x_train.shape, x_test.shape

"""Model Training 
XGBoos Regression
"""

# loading model
model = XGBRegressor()

# training the model
model.fit(x_train,y_train)

"""Evaluation

Prediction on training data
"""

# accuracy for prediction on training data
training_data_prediction = model.predict(x_train)

print(training_data_prediction)

# R squared error
score_1 = metrics.r2_score(y_train, training_data_prediction)

# Mean Absolute error
score_2 = metrics.mean_absolute_error(y_train, training_data_prediction)

print("R squared error : ",score_1)
print("Mean Absolute error",score_2)

"""Visualizing actual prices and predicted prices"""

plt.scatter(y_train,training_data_prediction)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Prices vs Predicted Prices")
plt.show()

"""Predicition on traning data"""

# accuracy for prediction on training data
testing_data_prediction = model.predict(x_test)

# R squared error
score_3 = metrics.r2_score(y_test, testing_data_prediction)

# Mean Absolute error
score_4 = metrics.mean_absolute_error(y_test, testing_data_prediction)

print("R squared error : ",score_3)
print("Mean Absolute error",score_4)

plt.scatter(y_test,testing_data_prediction)
plt.xlabel("Actual Prices in testing data")
plt.ylabel("Predicted Prices in testing data")
plt.title("Actual Prices vs Predicted Prices in testing data")
plt.show()